{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199dfc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "#Machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#Here we will extract both the Indian and Malay/Singaporean corpora. \n",
    "#We will extract the relevant columns and clean the data for preprocessing\n",
    "#Then we join all the rows together to train each respective model\n",
    "#Then we will do the reference model on some random corpus\n",
    "#Pipeline:\n",
    "#Get sentiment pair, pass through dialect identifier, then if malay/indian pass to their respective sentiment identifier\n",
    "#if not then pass to reference sentiment identifier\n",
    "#Also do a control passthrough where you just chuck the sentiment pair straight into the reference sentiment identifier\n",
    "#We should see an improvement over the control if my theory is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cfdb94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Size:  900 \n",
      "Head:\n",
      "      Rating                                             Review\n",
      "0  positive  Came here for the High Tea Great service espec...\n",
      "1  negative  5 stars for the service even though some of th...\n",
      "2  negative  Hi thank you for your service But i feel so so...\n",
      "3  negative  I have the worse buffer dinner ever so far The...\n",
      "4  positive  Thats are Known 5 Elmark  9H72   KDK  3 K14Y9 ...\n"
     ]
    }
   ],
   "source": [
    "#Read the file\n",
    "filepath = \"../Corpora/Sentiment-Malay/data_cleaned/GoogleReview_data_cleaned.csv\"\n",
    "df = pd.read_csv(filepath, sep=\",\", engine=\"python\", encoding=\"ISO-8859-1\", nrows=500)\n",
    "#Drop unused columns\n",
    "df=df.drop([\"Author\", \"Restaurant\", \"Location\"], axis=1)\n",
    "#Remove rows that contain review of 3.0 as these contain inconsistent sentiment\n",
    "df=df[df[\"Rating\"]!=3.0]\n",
    "print(type(df))\n",
    "df.loc[df[\"Rating\"] == 4.0, \"Rating\"] = \"positive\"\n",
    "df.loc[df[\"Rating\"] == 5.0, \"Rating\"] = \"positive\"\n",
    "df.loc[df[\"Rating\"] == 2.0, \"Rating\"] = \"negative\"\n",
    "df.loc[df[\"Rating\"] == 1.0, \"Rating\"] = \"negative\"\n",
    "df = df.replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "df.head()\n",
    "print(\"Size: \",df.size, \"\\nHead:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72f80fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c3547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f2f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "#Machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#Here we will extract both the Indian and Malay/Singaporean corpora. \n",
    "#We will extract the relevant columns and clean the data for preprocessing\n",
    "#Then we join all the rows together to train each respective model\n",
    "#Then we will do the reference model on some random corpus\n",
    "#Pipeline:\n",
    "#Get sentiment pair, pass through dialect identifier, then if malay/indian pass to their respective sentiment identifier\n",
    "#if not then pass to reference sentiment identifier\n",
    "#Also do a control passthrough where you just chuck the sentiment pair straight into the reference sentiment identifier\n",
    "#We should see an improvement over the control if my theory is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4a70530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9670ba57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Size:  5336 \n",
      "Head:\n",
      "      Rating                                             Review\n",
      "0  positive  Came here for the High Tea Great service espec...\n",
      "1  negative  5 stars for the service even though some of th...\n",
      "2  negative  Hi thank you for your service But i feel so so...\n",
      "3  negative  I have the worse buffer dinner ever so far The...\n",
      "4  positive  Thats are Known 5 Elmark  9H72   KDK  3 K14Y9 ...\n"
     ]
    }
   ],
   "source": [
    "#Read the Malay file\n",
    "filepath = \"../Corpora/Sentiment-Malay/data_cleaned/GoogleReview_data_cleaned.csv\"\n",
    "df = pd.read_csv(filepath, sep=\",\", engine=\"python\", encoding=\"ISO-8859-1\", nrows=3000)\n",
    "#Drop unused columns\n",
    "df=df.drop([\"Author\", \"Restaurant\", \"Location\"], axis=1)\n",
    "#Remove rows that contain review of 3.0 as these contain inconsistent sentiment\n",
    "df=df[df[\"Rating\"]!=3.0]\n",
    "print(type(df))\n",
    "df.loc[df[\"Rating\"] == 4.0, \"Rating\"] = \"positive\"\n",
    "df.loc[df[\"Rating\"] == 5.0, \"Rating\"] = \"positive\"\n",
    "df.loc[df[\"Rating\"] == 2.0, \"Rating\"] = \"negative\"\n",
    "df.loc[df[\"Rating\"] == 1.0, \"Rating\"] = \"negative\"\n",
    "df = df.replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "print(\"Size: \",df.size, \"\\nHead:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df75445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  3740 \n",
      "Head:\n",
      "      Rating                                             Review\n",
      "0  negative  I bought this hair oil after viewing so many g...\n",
      "1  positive  Used This Mama Earth Newly Launched Onion Oil ...\n",
      "2  negative  So bad productMy hair falling increase too muc...\n",
      "3  negative  Product just smells similar to navarathna hair...\n",
      "4  positive  I have been trying different onion oil for my ...\n"
     ]
    }
   ],
   "source": [
    "#Read the Indian file\n",
    "filepath = \"../Corpora/Sentiment-Indian/amazon_vfl_reviews.csv\"\n",
    "df = pd.read_csv(filepath, sep=\",\", engine=\"python\", encoding=\"ISO-8859-1\", nrows=2000)\n",
    "df=df.drop([\"asin\", \"name\", \"date\"], axis=1)\n",
    "df=df.rename(columns={\"rating\":\"Rating\"})\n",
    "df=df.rename(columns={\"review\":\"Review\"})\n",
    "df=df[df[\"Rating\"]!=3.0]\n",
    "df.loc[df[\"Rating\"] == 4.0, \"Rating\"] = \"positive\"\n",
    "df.loc[df[\"Rating\"] == 5.0, \"Rating\"] = \"positive\"\n",
    "df.loc[df[\"Rating\"] == 2.0, \"Rating\"] = \"negative\"\n",
    "df.loc[df[\"Rating\"] == 1.0, \"Rating\"] = \"negative\"\n",
    "df = df.replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "print(\"Size: \",df.size, \"\\nHead:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "03834d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>DVD Player crapped out after one year: I also ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating                                             Review\n",
       "0  positive  One of the best game music soundtracks - for a...\n",
       "1  negative  Batteries died within a year ...: I bought thi...\n",
       "2  positive  works fine, but Maha Energy is better: Check o...\n",
       "3  positive  Great for the non-audiophile: Reviewed quite a...\n",
       "4  negative  DVD Player crapped out after one year: I also ..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the Reference file\n",
    "\n",
    "# Read the text file and split each line into label and feature\n",
    "#with open(filepath, 'r', encoding=\"ISO-8859-1\") as file:\n",
    "    #data = [line.strip().split() for line in file]\n",
    "\n",
    "# Create a DataFrame from the data, specifying the order of the columns\n",
    "#df = pd.DataFrame(data, columns=['label', 'feature'])\n",
    "\n",
    "\n",
    "filepath = \"../Corpora/Sentiment-Reference/test.txt.txt\"\n",
    "df = pd.DataFrame()\n",
    "df[\"X\"] = pd.read_csv(filepath, sep=\"\\t\", engine=\"python\", encoding=\"ISO-8859-1\", nrows=5000)\n",
    "df[[\"Rating\", \"Review\"]] = df[\"X\"].str.split(\" \", n=1, expand=True)\n",
    "df.drop(\"X\", axis=1, inplace=True)\n",
    "df.loc[df[\"Rating\"] == \"__label__1\", \"Rating\"] = \"negative\"\n",
    "df.loc[df[\"Rating\"] == \"__label__2\", \"Rating\"] = \"positive\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c90aede0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2175    Decent: After having a lot of trouble finding ...\n",
      "3156    I never thought Meryl Streep could give a \"bad...\n",
      "337     Great eye candy, but compares poorly to the fi...\n",
      "444     Kingston Technology KVR133X64C3/ 256 PC133 256...\n",
      "2334    Could Have Been A Fun Movie For The Kids: With...\n",
      "                              ...                        \n",
      "1862    Batman Scores A Win: Christian Bale is great a...\n",
      "1028    Memory Lane: I saw the movie based on this boo...\n",
      "4430    OUTSTANDING HORROR MOVIE- AN ORIGINAL: This ha...\n",
      "3025    This book is thorough but poorly written.: It ...\n",
      "1807    urethane coating, how about all urethane: It i...\n",
      "Name: Review, Length: 1000, dtype: object\n",
      "Accuracy: 82.30%\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "#Make Malay, Indian, and Reference Model\n",
    "#Malay\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=5, max_df=0.8, ngram_range=[1,3])\n",
    "dfs_x = df[\"Review\"]\n",
    "dfs_y = df[\"Rating\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfs_x, dfs_y, test_size=0.2, random_state=4)\n",
    "print(x_test)\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "#clf = MultinomialNB()\n",
    "#clf = SVC(kernel=\"sigmoid\")\n",
    "#clf = LinearSVC()\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dbce7331",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 300: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [138]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Corpora/Sentiment-Reference/test.txt.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Keep every other line\u001b[39;00m\n\u001b[0;32m      5\u001b[0m lines \u001b[38;5;241m=\u001b[39m lines[::\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 300: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "with open('../Corpora/Sentiment-Reference/test.txt.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Keep every other line\n",
    "lines = lines[::2]\n",
    "\n",
    "# Write the modified lines back to a new file\n",
    "with open('test.txt.txt', 'w') as file:\n",
    "    file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a54252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
